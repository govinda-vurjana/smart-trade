import time
import pandas as pd
from tqdm import tqdm  # Real-time progress bar
from DataReader import DataReader
from TickTradingEnv import train_agent, TradingEnv, PPO
import torch.optim as optim
from TCPClient import TCPClient

# âœ… Available Markets
markets = {
    1: "usd_inr",
    2: "usd_pkr",
    3: "usd_brl",
    4: "nzd_cad",
    5: "usd_dzd",
    6: "eur_usd"
}

# âœ… Market Selection
def select_market():
    print("\nSelect a target market:")
    for num, market in markets.items():
        print(f"{num}. {market.upper()}")  
    
    while True:
        try:
            choice = int(input("Enter the market number (1-6): "))
            if choice in markets:
                print(f"âœ… Selected Market: {markets[choice].upper()}")
                return markets[choice]
            print("âŒ Invalid choice. Please enter a number between 1-6.")
        except ValueError:
            print("âŒ Invalid input. Please enter a number.")

# âœ… Get Selected Market
market_identifier = select_market()

# âœ… Initialize Environment & Model (Persistent)
env = TradingEnv(market_identifier)
model = PPO(input_dim=6)  
optimizer = optim.Adam(model.parameters(), lr=0.001)

# âœ… Load Model Checkpoint (if available)
env.load_model(model)

# âœ… Function Called When Data is Ready
def data_ready_for_prediction(min, dataReader, df):
    # print("âœ… Data ready for RL. Resampling and feature engineering...")

    state, tail = dataReader.fetch_recent_data(min, df)

    if not state.empty:
        print("ğŸ“Š Training RL Agent...")
        train_agent(state, tail, env, model, optimizer)
    else:
        print("âš ï¸ No State Info received.")

# âœ… Path to the CSV file
file_path = r"cleaned_file.csv"

# âœ… Read CSV
df = pd.read_csv(file_path)

# âœ… Define chunk size (48 rows = 4 minutes)
chunk_size = 48
dataReader = DataReader()

total_chunks = (len(df) + chunk_size - 1) // chunk_size  # Total number of chunks
start_time = time.time()

# âœ… Iterate through DataFrame in 48-row chunks
for start in tqdm(range(0, len(df), chunk_size), desc="ğŸ“Š Processing Data", unit=" chunk"):
    chunk_df = df.iloc[start:start + chunk_size]  # Select 48-row chunk
    
    # Print detailed logs occasionally
    if start % (chunk_size * 5) == 0:  
        print(f"\nğŸ“Œ Processing rows {start} to {start + chunk_size - 1}")
    
    # âœ… Process Data Chunk
    data_ready_for_prediction(3, dataReader, chunk_df)

    # Print elapsed time occasionally
    if start % (chunk_size * 10) == 0:  
        elapsed_time = time.time() - start_time
        print(f"â³ Elapsed Time: {elapsed_time:.2f} sec | ğŸ”„ Chunks Remaining: {total_chunks - (start // chunk_size + 1)}")

# âœ… Final Summary
total_elapsed_time = time.time() - start_time
print(f"\nğŸ‰ All data processed successfully in {total_elapsed_time:.2f} seconds!")
